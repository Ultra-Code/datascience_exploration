{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5a54767",
   "metadata": {
    "id": "c5a54767"
   },
   "source": [
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/Python-Notebook-Banners/Examples.png\"  style=\"display: block; margin-left: auto; margin-right: auto;\";/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diagnostic-privacy",
   "metadata": {
    "id": "diagnostic-privacy",
    "papermill": {
     "duration": 0.012314,
     "end_time": "2021-06-14T11:19:49.342358",
     "exception": false,
     "start_time": "2021-06-14T11:19:49.330044",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction\n",
    "\n",
    "The followig aims to get you up and running with the predict.\n",
    "Make a copy of the notebook and run all cells. We will also show you how to get your submission file from kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-musical",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-06-14T11:19:49.368292Z",
     "iopub.status.busy": "2021-06-14T11:19:49.367341Z",
     "iopub.status.idle": "2021-06-14T11:19:49.377976Z",
     "shell.execute_reply": "2021-06-14T11:19:49.378408Z",
     "shell.execute_reply.started": "2021-06-14T11:18:06.298343Z"
    },
    "id": "seasonal-musical",
    "papermill": {
     "duration": 0.024972,
     "end_time": "2021-06-14T11:19:49.378659",
     "exception": false,
     "start_time": "2021-06-14T11:19:49.353687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alien-ability",
   "metadata": {
    "id": "alien-ability",
    "papermill": {
     "duration": 0.011326,
     "end_time": "2021-06-14T11:19:49.401974",
     "exception": false,
     "start_time": "2021-06-14T11:19:49.390648",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Installing packages\n",
    "Please download all relevant packages in. There is no terminal so you will pip install everything.\n",
    "\n",
    "You can find a list of recommended install from the Intro to Recommender sysytem notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third-pregnancy",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-14T11:19:49.433460Z",
     "iopub.status.busy": "2021-06-14T11:19:49.432872Z",
     "iopub.status.idle": "2021-06-14T11:19:50.487854Z",
     "shell.execute_reply": "2021-06-14T11:19:50.487374Z",
     "shell.execute_reply.started": "2021-06-06T09:45:12.506175Z"
    },
    "id": "third-pregnancy",
    "papermill": {
     "duration": 1.07453,
     "end_time": "2021-06-14T11:19:50.487990",
     "exception": false,
     "start_time": "2021-06-14T11:19:49.413460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install packages here\n",
    "# Packages for data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from sklearn import preprocessing\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy as sp\n",
    "\n",
    "\n",
    "# Packages for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Packages for modeling\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import KNNBasic\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise import SVD\n",
    "from surprise import SVDpp\n",
    "from surprise import NMF\n",
    "from surprise import SlopeOne\n",
    "from surprise import CoClustering\n",
    "import heapq\n",
    "\n",
    "# Packages for model evaluation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from time import time\n",
    "\n",
    "# Package to suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Packages for saving models\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reasonable-space",
   "metadata": {
    "id": "reasonable-space",
    "papermill": {
     "duration": 0.011369,
     "end_time": "2021-06-14T11:19:50.511223",
     "exception": false,
     "start_time": "2021-06-14T11:19:50.499854",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Reading in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-favorite",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-14T11:19:50.540712Z",
     "iopub.status.busy": "2021-06-14T11:19:50.540043Z",
     "iopub.status.idle": "2021-06-14T11:20:08.370886Z",
     "shell.execute_reply": "2021-06-14T11:20:08.371333Z",
     "shell.execute_reply.started": "2021-06-06T09:35:50.49335Z"
    },
    "id": "charming-favorite",
    "papermill": {
     "duration": 17.847754,
     "end_time": "2021-06-14T11:20:08.371525",
     "exception": false,
     "start_time": "2021-06-14T11:19:50.523771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/kaggle/input/alx-movie-recommendation-project-2024/train.csv')\n",
    "movies_df = pd.read_csv('/kaggle/input/alx-movie-recommendation-project-2024/movies.csv')\n",
    "imdb_df = pd.read_csv('/kaggle/input/alx-movie-recommendation-project-2024/imdb_data.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/alx-movie-recommendation-project-2024/test.csv')\n",
    "links_df = pd.read_csv('/kaggle/input/alx-movie-recommendation-project-2024/links.csv')\n",
    "tags = pd.read_csv('/kaggle/input/alx-movie-recommendation-project-2024/tags.csv')\n",
    "genome_scores = pd.read_csv('/kaggle/input/alx-movie-recommendation-project-2024/genome_scores.csv')\n",
    "genome_tags = pd.read_csv('/kaggle/input/alx-movie-recommendation-project-2024/genome_tags.csv')\n",
    "sample_submissions = pd.read_csv('/kaggle/input/alx-movie-recommendation-project-2024/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-desperate",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-14T11:20:08.397787Z",
     "iopub.status.busy": "2021-06-14T11:20:08.397272Z",
     "iopub.status.idle": "2021-06-14T11:20:08.420726Z",
     "shell.execute_reply": "2021-06-14T11:20:08.420308Z",
     "shell.execute_reply.started": "2021-06-06T09:36:13.589735Z"
    },
    "id": "alien-desperate",
    "papermill": {
     "duration": 0.037338,
     "end_time": "2021-06-14T11:20:08.420852",
     "exception": false,
     "start_time": "2021-06-14T11:20:08.383514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporated-respondent",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-14T11:20:08.453945Z",
     "iopub.status.busy": "2021-06-14T11:20:08.453387Z",
     "iopub.status.idle": "2021-06-14T11:20:08.456331Z",
     "shell.execute_reply": "2021-06-14T11:20:08.455811Z",
     "shell.execute_reply.started": "2021-06-06T10:02:45.481641Z"
    },
    "id": "incorporated-respondent",
    "papermill": {
     "duration": 0.023503,
     "end_time": "2021-06-14T11:20:08.456451",
     "exception": false,
     "start_time": "2021-06-14T11:20:08.432948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "movies_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parliamentary-saturn",
   "metadata": {
    "id": "parliamentary-saturn",
    "papermill": {
     "duration": 0.011896,
     "end_time": "2021-06-14T11:20:08.480518",
     "exception": false,
     "start_time": "2021-06-14T11:20:08.468622",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## EDA\n",
    "\n",
    "\n",
    "### Outliers\n",
    "- **Identify outliers**: Outliers are data points that differ significantly from other observations. They can skew and mislead the training process of a machine learning model.\n",
    "- **Detecting outliers**: Use statistical methods such as Z-scores or IQR (Interquartile Range) to detect outliers.\n",
    "- **Handling outliers**: Decide whether to remove or transform the outliers depending on their impact on the dataset.\n",
    "\n",
    "### Understanding Relationships Between Various Attributes and Structure of the Data\n",
    "- **Correlation Analysis**: Use correlation matrices to understand the relationships between numerical attributes.\n",
    "- **Visualization Techniques**: Employ scatter plots, pair plots, and heatmaps to visualize and explore relationships.\n",
    "- **Data Structure**: Understand the structure of the data, including the distribution of values and the presence of any missing values.\n",
    "\n",
    "### Recognizing Important Variables\n",
    "- **Feature Importance**: Use techniques like Random Forests, Gradient Boosting, or SHAP values to determine feature importance.\n",
    "- **Domain Knowledge**: Incorporate domain expertise to identify which variables are likely to be important.\n",
    "- **Statistical Tests**: Conduct statistical tests to identify variables that have significant effects on the target variable.\n",
    "\n",
    "By understanding the data through these steps, we ensure a robust foundation for building and evaluating machine learning models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d42217",
   "metadata": {
    "id": "66d42217"
   },
   "source": [
    "**Lets Check whether or not we have any missing values in our dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e31dda3",
   "metadata": {
    "id": "2e31dda3"
   },
   "outputs": [],
   "source": [
    "print(\"Train: \")\n",
    "print(str(train_df.isnull().sum()))\n",
    "print(\"************\")\n",
    "print(\"Test: \")\n",
    "print(str(test_df.isnull().sum()))\n",
    "print(\"************\")\n",
    "print(\"Movies: \")\n",
    "print(str(movies_df.isnull().sum()))\n",
    "print(\"************\")\n",
    "print(\"Links: \")\n",
    "print(str(links_df.isnull().sum()))\n",
    "print(\"************\")\n",
    "print(\"IMDB: \")\n",
    "print(str(imdb_df.isnull().sum()))\n",
    "print(\"************\")\n",
    "print(\"Genome scores: \")\n",
    "print(str(genome_scores.isnull().sum()))\n",
    "print(\"************\")\n",
    "print(\"Genome tags: \")\n",
    "print(str(genome_tags.isnull().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-cooler",
   "metadata": {
    "id": "french-cooler",
    "papermill": {
     "duration": 0.012939,
     "end_time": "2021-06-14T11:20:09.159029",
     "exception": false,
     "start_time": "2021-06-14T11:20:09.146090",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f5e907",
   "metadata": {
    "id": "58f5e907"
   },
   "source": [
    "Data preparation is the process of preparing raw data so that it is suitable for further processing and analysis. Key steps include:\n",
    "\n",
    "- **Collecting**: Gathering raw data from various sources.\n",
    "- **Cleaning**: Removing or correcting any errors or inconsistencies in the data. This includes handling missing values, correcting data types, and removing duplicates.\n",
    "- **Labeling**: Annotating data with labels that are required for supervised machine learning tasks. This involves identifying and marking the target variable.\n",
    "- **Transforming**: Converting raw data into a format that is suitable for analysis. This includes normalization, scaling, encoding categorical variables, and feature engineering.\n",
    "- **Exploring**: Analyzing the data to understand its structure and relationships. This step includes generating descriptive statistics and visualizing the data to identify patterns and insights.\n",
    "- **Visualizing**: Creating graphical representations of the data to better understand distributions, trends, and relationships among variables. Common techniques include histograms, bar charts, scatter plots, and heatmaps.\n",
    "\n",
    "By following these steps, raw data is transformed into a structured format that is ready for machine learning algorithms and further analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8bebfc",
   "metadata": {
    "id": "2d8bebfc"
   },
   "outputs": [],
   "source": [
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85d2997",
   "metadata": {
    "id": "f85d2997"
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa34c6a",
   "metadata": {
    "id": "3fa34c6a"
   },
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-retro",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-14T11:20:09.188377Z",
     "iopub.status.busy": "2021-06-14T11:20:09.187869Z",
     "iopub.status.idle": "2021-06-14T11:20:09.190673Z",
     "shell.execute_reply": "2021-06-14T11:20:09.191184Z",
     "shell.execute_reply.started": "2021-06-06T09:47:42.880914Z"
    },
    "id": "polish-retro",
    "papermill": {
     "duration": 0.018806,
     "end_time": "2021-06-14T11:20:09.191326",
     "exception": false,
     "start_time": "2021-06-14T11:20:09.172520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create dataframe containing only the movieId and genres\n",
    "movies_genres = pd.DataFrame(movies_df[['movieId', 'genres']],\n",
    "                             columns=['movieId', 'genres'])\n",
    "\n",
    "# Split genres seperated by \"|\" and create a list containing the genres allocated to each movie\n",
    "movies_genres.genres = movies_genres.genres.apply(lambda x: x.split('|'))\n",
    "\n",
    "# Create expanded dataframe where each movie-genre combination is in a seperate row\n",
    "movies_genres = pd.DataFrame([(tup.movieId, d) for tup in movies_genres.itertuples() for d in tup.genres],\n",
    "                             columns=['movieId', 'genres'])\n",
    "\n",
    "movies_genres.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af5aa4f",
   "metadata": {
    "id": "8af5aa4f"
   },
   "source": [
    "**Lets plot genres from most common to least common**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b7a1f4",
   "metadata": {
    "id": "37b7a1f4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot = plt.figure(figsize=(15, 10))\n",
    "plt.title('Most common genres\\n', fontsize=20)\n",
    "sns.countplot(y=\"genres\", data=movies_genres,\n",
    "              order=movies_genres['genres'].value_counts(ascending=False).index,\n",
    "              palette='Reds_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-episode",
   "metadata": {
    "id": "agricultural-episode",
    "papermill": {
     "duration": 0.013398,
     "end_time": "2021-06-14T11:20:09.218336",
     "exception": false,
     "start_time": "2021-06-14T11:20:09.204938",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Modelling phase\n",
    " You only need to apply one version\n",
    "be it Content based or Collabrative method\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-uganda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-14T11:20:09.248235Z",
     "iopub.status.busy": "2021-06-14T11:20:09.247715Z",
     "iopub.status.idle": "2021-06-14T11:20:09.250599Z",
     "shell.execute_reply": "2021-06-14T11:20:09.251034Z",
     "shell.execute_reply.started": "2021-06-06T09:55:07.155448Z"
    },
    "id": "relevant-uganda",
    "papermill": {
     "duration": 0.019188,
     "end_time": "2021-06-14T11:20:09.251198",
     "exception": false,
     "start_time": "2021-06-14T11:20:09.232010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from surprise import Reader, Dataset, SVD, accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Sample books data\n",
    "books_data = {\n",
    "    'bookId': [1, 2, 3, 4, 5, 6, 7],\n",
    "    'title': ['To Kill a Mockingbird', '1984', 'The Great Gatsby', 'Pride and Prejudice', 'The Catcher in the Rye', 'Animal farm'\n",
    "              ,'Harry Potter']\n",
    "}\n",
    "\n",
    "# Create the books DataFrame\n",
    "books = pd.DataFrame(books_data)\n",
    "\n",
    "# Sample user profiles\n",
    "user_profiles = {\n",
    "    1: {'bookId': [2, 3, 4], 'rating': [5, 4, 3]},\n",
    "    2: {'bookId': [1, 3, 5], 'rating': [4, 5, 3]}\n",
    "}\n",
    "\n",
    "# Combine user profiles into a single DataFrame\n",
    "all_ratings = []\n",
    "\n",
    "for user_id, profile in user_profiles.items():\n",
    "    for book_id, rating in zip(profile['bookId'], profile['rating']):\n",
    "        all_ratings.append({'userId': user_id, 'bookId': book_id, 'rating': rating})\n",
    "\n",
    "ratings_df = pd.DataFrame(all_ratings)\n",
    "\n",
    "# Define the Reader and Dataset\n",
    "reader = Reader(rating_scale=(0.5, 5.0))\n",
    "data = Dataset.load_from_df(ratings_df[['userId', 'bookId', 'rating']], reader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "n-LXiY5DoGrp",
   "metadata": {
    "id": "n-LXiY5DoGrp"
   },
   "source": [
    "## Lets Build and Evaluate Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d68a1e7",
   "metadata": {
    "id": "1d68a1e7"
   },
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "\n",
    "# Train the SVD model\n",
    "svd = SVD()\n",
    "svd.fit(trainset)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = svd.test(testset)\n",
    "\n",
    "# Compute and print the RMSE\n",
    "rmse = accuracy.rmse(predictions)\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n",
    "pred = pd.DataFrame(predictions)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb0645b",
   "metadata": {
    "id": "6fb0645b"
   },
   "source": [
    "## Recommendation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84999207",
   "metadata": {
    "id": "84999207"
   },
   "outputs": [],
   "source": [
    "# Function to get collaborative recommendations for a user profile\n",
    "def get_collaborative_recommendations(user_id, svd, books, ratings_df, n=10):\n",
    "    recommendations = []\n",
    "    book_ids = books['bookId'].unique()\n",
    "\n",
    "    for book_id in book_ids:\n",
    "        prediction = svd.predict(user_id, book_id)\n",
    "        actual_rating = ratings_df[(ratings_df['userId'] == user_id) & (ratings_df['bookId'] == book_id)]['rating']\n",
    "        actual_rating = actual_rating.values[0] if not actual_rating.empty else None\n",
    "        recommendations.append((books[books['bookId'] == book_id]['title'].values[0], prediction.est, actual_rating))\n",
    "\n",
    "    recommendations = sorted(recommendations, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return recommendations[:n]\n",
    "\n",
    "# Generate recommendations for each user profile and collect them in a list\n",
    "all_recommendations = []\n",
    "\n",
    "for user_id in user_profiles.keys():\n",
    "    recommendations = get_collaborative_recommendations(user_id, svd, books, ratings_df)\n",
    "    for title, predicted_rating, actual_rating in recommendations:\n",
    "        all_recommendations.append({\n",
    "            'userId': user_id,\n",
    "            'Recommended Book': title,\n",
    "            'Predicted_Rating': predicted_rating,\n",
    "            'Actual Rating': actual_rating\n",
    "        })\n",
    "\n",
    "# Convert the list of recommendations to a DataFrame\n",
    "recommendations_df = pd.DataFrame(all_recommendations)\n",
    "\n",
    "recommendations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-burton",
   "metadata": {
    "id": "robust-burton",
    "papermill": {
     "duration": 0.013848,
     "end_time": "2021-06-14T11:20:09.278819",
     "exception": false,
     "start_time": "2021-06-14T11:20:09.264971",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Generate your outputs here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustained-lawsuit",
   "metadata": {
    "id": "sustained-lawsuit",
    "papermill": {
     "duration": 0.013303,
     "end_time": "2021-06-14T11:20:09.305786",
     "exception": false,
     "start_time": "2021-06-14T11:20:09.292483",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Prepare Submission File\n",
    "We make submissions in CSV files. Your submissions usually have two columns: an ID column and a prediction column. The ID field comes from the test data (keeping whatever name the ID field had in that data, which for the data is the string 'Id'). The prediction column will use the name of the target field.\n",
    "\n",
    "We will create a DataFrame with this data, and then use the dataframe's to_csv method to write our submission file. Explicitly include the argument index=False to prevent pandas from adding another column in our csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "major-gossip",
   "metadata": {
    "id": "major-gossip",
    "papermill": {
     "duration": 0.019235,
     "end_time": "2021-06-14T11:20:09.338682",
     "exception": false,
     "start_time": "2021-06-14T11:20:09.319447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# This is an example\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m my_submission \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m: recommendations_df\u001b[38;5;241m.\u001b[39muserId,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m'\u001b[39m: recommendations_df\u001b[38;5;241m.\u001b[39mPredicted_Rating})\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#you could use any filename. We choose submission here\u001b[39;00m\n\u001b[1;32m      4\u001b[0m my_submission\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubmission.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# This is an example\n",
    "my_submission = pd.DataFrame({'id': recommendations_df.userId,'predict': recommendations_df.Predicted_Rating})\n",
    "#you could use any filename. We choose submission here\n",
    "my_submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1661282b",
   "metadata": {
    "id": "1661282b",
    "papermill": {
     "duration": 0.013439,
     "end_time": "2021-06-14T11:20:09.498408",
     "exception": false,
     "start_time": "2021-06-14T11:20:09.484969",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Tips\n",
    "- NB:Read the description well\n",
    "    - REMEMBER: Concatenated ID\n",
    "    - Evatualtion metrics\n",
    "- Sampling is your friend -> start small and scale up\n",
    "- Data ingestioon, pleasse ensure the correct path is dependant on the environment\n",
    "- Ensure test output matches dimension of test set for Kaggle submission\n",
    "- 20 Submissions per day\n",
    "- This is individual project\n",
    "- Ensure email correlates to Athena for effective tracking\n",
    "- If you use a shuffler ensure test output aligns with test sample ordering\n",
    "  - (from sklearn.utils import shuffle), for randomness\n",
    "- Make sure your notebook is in the same folder\n",
    "- Analyse your data well\n",
    "- Make sure you have gone through your content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JPdS9m4cKABb",
   "metadata": {
    "id": "JPdS9m4cKABb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 27.559281,
   "end_time": "2021-06-14T11:20:10.319911",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-14T11:19:42.760630",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
