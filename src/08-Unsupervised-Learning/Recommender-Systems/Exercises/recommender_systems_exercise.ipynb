{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/Python-Notebook-Banners/Exercise.png\"  style=\"display: block; margin-left: auto; margin-right: auto;\";/>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Recommender systems\n",
    "© ExploreAI Academy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we will build a content-based recommendation system using a dataset of Netflix titles. We will preprocess the text data, convert it into numerical features with TF-IDF, and compute item similarities to generate recommendations. This hands-on activity will help us understand and implement key techniques in content-based filtering.\n",
    "\n",
    "## Learning objectives\n",
    "\n",
    "By the end of this exercise, you should be able to:\n",
    "* Understand content-based recommendation systems.\n",
    "* Clean and preprocess text data.\n",
    "* Convert text data into numerical features using TF-IDF.\n",
    "* Compute item similarities using cosine similarity.\n",
    "* Build and evaluate a content-based recommendation model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook, we will build a `content-based recommendation system` using the `Netflix` dataset. The primary goal of this task is to recommend similar titles to users based on the attributes of the media they have already interacted with. This will enhance the user experience by providing personalised content recommendations, thereby increasing user engagement and satisfaction. By predicting which titles a user might enjoy based on their previous interactions, content-based recommendation systems help platforms like `Netflix` keep users engaged and encourage them to explore a broader range of content.\n",
    "\n",
    "The dataset is derived from Netflix's collection of movies and TV shows. This dataset includes various attributes for each title, such as:\n",
    "\n",
    "* show_id: Unique identifier for each title.\n",
    "* type: The type of media (e.g., Movie, TV Show).\n",
    "* title: The name of the media.\n",
    "* director: Directors involved in the media.\n",
    "* cast: Main actors involved in the media.\n",
    "* country: Countries where the media was produced.\n",
    "* date_added: The date when the media was added to Netflix.\n",
    "* release_year: The year the media was released.\n",
    "* rating: The rating given to the media.\n",
    "* duration: Duration of the media (e.g., 90 min, 1 Season).\n",
    "* listed_in: Categories or genres the media belongs to.\n",
    "* description: Brief summary or synopsis of the media.\n",
    "\n",
    "The data was collected to provide a comprehensive overview of the available media on `Netflix`. It allows for detailed analysis and exploration of the media's attributes, which is essential for building a recommendation system.\n",
    "\n",
    "Let's dive in!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libraries and read the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "# For text handling and regular expressions\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # For converting text to numerical data\n",
    "\n",
    "# For computing cosine similarity\n",
    "from sklearn.metrics.pairwise import linear_kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://raw.githubusercontent.com/Explore-AI/Public-Data/master/Data/unsupervised_sprint/netflix_titles.csv', index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "In this exercise, we focus on the relevant columns `cast`, `title`, `description`, and `listed_in` because these textual features provide detailed descriptions and attributes essential for capturing the content similarities between media items. These columns contain detailed information about what the media is about, who stars in it, and its genres, which are crucial for generating meaningful recommendations in a content-based filtering approach."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Data cleaning and preprocessing\n",
    "\n",
    "Before proceeding with our recommender system, we need to clean and process our data first to get the most accurate results. \n",
    "\n",
    "We need to do the following:\n",
    "\n",
    "* Remove rows with missing or NaN values.\n",
    "<br>\n",
    "<br>\n",
    "* Remove punctuation and extra spaces in the text data. This helps to standardise and clean the text, ensuring consistency in the dataset and facilitating accurate analysis and modelling by eliminating unnecessary noise and variations in the text.\n",
    "\n",
    "**Hint**: \n",
    "> * For all the text columns, remove all characters that are not alphanumeric or whitespace.\n",
    "> * For the 'cast' column, first remove all spaces and then replace commas with spaces. This ensures that the cast members' names are treated as single entities separated by spaces.\n",
    "<br>\n",
    "<br>\n",
    "* Combine the columns `listed_in`, `cast`, `title`, and `description` into a single feature for the recommendation system. This creates a richer and more complete representation of each item, enhancing the effectiveness of the recommendation system by allowing it to consider all aspects of the content simultaneously.<br> \n",
    "**Hint**: Remember to drop the individual columns as they are now combined into one.\n",
    "<br>\n",
    "<br>   \n",
    "* Drop the rest of the columns to streamline and focus on the most relevant data for our recommendation model so that we are only left with the `type`, `title`, and `combined` columns with `type` and `title` providing context and identification, and `combined` serving as the main feature for calculating similarities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Feature extraction\n",
    "Next, we want to convert the combined text feature into numerical features using TF-IDF.\n",
    "This enables the application of mathematical and statistical techniques for measuring similarities between different media items. In its raw form, text data cannot be directly used for similarity calculations or machine learning algorithms. By transforming the text into numerical representations, we can leverage these techniques to analyse and compare the content effectively.\n",
    "\n",
    "* Utilise TF-IDF to convert the `combined` column into numerical vectors, which represent the importance of words in the document. Initialise your TF-IDF Vectoriser without specifying any parameters, which means it will default to single-word tokens.\n",
    "* Compute the cosine similarity between these vectors to measure how similar the titles are.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Building the recommendation function\n",
    "\n",
    "Now, we can generate recommendations based on cosine similarity.\n",
    "\n",
    "Define a function that, given a title, finds similar titles by looking up their cosine similarity scores and returns the top 10 recommendations based on these scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Test the recommender\n",
    "\n",
    "Say you are trying to get recommendations for what movie to watch, and you particularly enjoyed the film `The Crown`. Run our recommender for this title and see what recommendations we get. \n",
    "\n",
    "Would you want to watch any of these titles?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solutions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaN values in the specified columns to ensure we have complete data for these important attributes\n",
    "data.dropna(subset=['cast', 'title', 'description', 'listed_in'], inplace=True, axis=0)\n",
    "\n",
    "# Reset the index after dropping rows to maintain a clean DataFrame\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "# Clean text data by removing punctuation and extra spaces to ensure consistency in the text data\n",
    "data['listed_in'] = [re.sub(r'[^\\w\\s]', '', t) for t in data['listed_in']] # Remove punctuation from 'listed_in' column\n",
    "data['cast'] = [re.sub(',', ' ', re.sub(' ', '', t)) for t in data['cast']] # Replace commas with spaces in 'cast' column\n",
    "data['description'] = [re.sub(r'[^\\w\\s]', '', t) for t in data['description']] # Remove punctuation from 'description'\n",
    "data['title'] = [re.sub(r'[^\\w\\s]', '', t) for t in data['title']] # Remove punctuation from 'title'\n",
    "\n",
    "# Combine the cleaned text data into a single 'combined' feature\n",
    "# This helps in creating a unified representation of each media item for the recommendation system\n",
    "data[\"combined\"] = data['listed_in'] + ' ' + data['cast'] + ' ' + data['title'] + ' ' + data['description']\n",
    "\n",
    "# Drop the individual columns as they are now represented in the 'combined' feature\n",
    "# Also drop other columns that are not used in the recommendation model\n",
    "data.drop(['director', 'country', 'date_added', 'release_year', 'rating', 'duration', 'listed_in', 'cast', 'description'], axis=1, inplace=True)\n",
    "\n",
    "# Display the first few rows of the cleaned data to verify the changes\n",
    "data.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note!!**\n",
    "\n",
    "It's important to acknowledge that dropping NaN values can potentially lead to information loss, and in situations where missing data follows a specific trend or pattern, dropping NaNs might not be ideal as it could bias the analysis. In such cases, other strategies like imputation or handling missing values through specialised techniques might be more suitable. Ultimately, the choice between dropping NaN values and handling them through imputation or other methods depends on the data, the specific context of the analysis and the goals of the study."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the combined text data to numerical vectors\n",
    "matrix = vectorizer.fit_transform(data[\"combined\"])\n",
    "\n",
    "# Compute cosine similarities between the vectors\n",
    "#cosine_similarities = linear_kernel(matrix, matrix)\n",
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "cosine_similarities = cosine_similarity(matrix, matrix)\n",
    "\n",
    "# Extract the title column for later use in recommendations\n",
    "movie_title = data['title']\n",
    "\n",
    "# Create a series to map each title to its index in the dataset\n",
    "indices = pd.Series(data.index, index=data['title'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note!!**\n",
    "\n",
    "Adjusting parameters like the n-grams in the vectoriser could capture more complex relationships, such as those between cast members. This could potentially lead to recommendations that reflect relationships like sequels or movies with similar casts. Exploring different n-gram ranges can be valuable for enhancing the recommendation system’s performance and capturing nuanced similarities within the text data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the recommendation function\n",
    "def content_recommender(title):\n",
    "    # Get the index of the given title\n",
    "    idx = indices[title]\n",
    "    \n",
    "    # Get the pairwise similarity scores of all titles with the given title\n",
    "    sim_scores = list(enumerate(cosine_similarities[idx]))\n",
    "    \n",
    "    # Sort the titles based on similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get the indices of the most similar titles\n",
    "    sim_scores = sim_scores[1:11]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    \n",
    "    # Return the titles of the most similar titles\n",
    "    return movie_title.iloc[movie_indices]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the recommendation function\n",
    "content_recommender('The Crown')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \n",
    "\n",
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/ExploreAI_logos/EAI_Blue_Dark.png\"  style=\"width:200px\";/>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
