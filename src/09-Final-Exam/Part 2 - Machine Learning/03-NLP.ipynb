{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "35b64f6b-3e1d-4c09-b560-b90ee1d8a54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk import SnowballStemmer, PorterStemmer, LancasterStemmer, download\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from string import punctuation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "af5da71d-7c39-49dd-a499-682abd02b5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ultracode/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download(['stopwords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "82fa5cb1-668d-402f-825b-021afe7c4d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I/E</th>\n",
       "      <th>N/S</th>\n",
       "      <th>T/F</th>\n",
       "      <th>J/P</th>\n",
       "      <th>Essay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>S</td>\n",
       "      <td>T</td>\n",
       "      <td>J</td>\n",
       "      <td>My first 4 months at the EDSA have been filled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>I joined the academy being at a crossroads of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>so far my experience has been positive and i c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>I have been very fortunate to have the opportu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>J</td>\n",
       "      <td>Looking back to when one got to the academy an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  I/E N/S T/F J/P                                              Essay\n",
       "0   I   S   T   J  My first 4 months at the EDSA have been filled...\n",
       "1   I   N   F   J  I joined the academy being at a crossroads of ...\n",
       "2   E   N   F   J  so far my experience has been positive and i c...\n",
       "3   I   N   F   J  I have been very fortunate to have the opportu...\n",
       "4   I   N   T   J  Looking back to when one got to the academy an..."
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay = pd.read_csv(\"./Dataset/Essay_data.csv\")\n",
    "essay.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c245421e-a06d-465c-bc50-fc80ecafc85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94, 5)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "744fc332-f2c5-4805-942a-ba48dfc6b15b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I/E</th>\n",
       "      <th>N/S</th>\n",
       "      <th>T/F</th>\n",
       "      <th>J/P</th>\n",
       "      <th>Essay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>S</td>\n",
       "      <td>T</td>\n",
       "      <td>J</td>\n",
       "      <td>My first 4 months at the EDSA have been filled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>I joined the academy being at a crossroads of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>so far my experience has been positive and i c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>I have been very fortunate to have the opportu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>J</td>\n",
       "      <td>Looking back to when one got to the academy an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>I</td>\n",
       "      <td>S</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>My experience at the Explore Data Science Acad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>P</td>\n",
       "      <td>A new city, new people and a completely new en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>J</td>\n",
       "      <td>My experience at the academy has been one of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>I</td>\n",
       "      <td>S</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>After spending a year at home while it was jus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>E</td>\n",
       "      <td>S</td>\n",
       "      <td>F</td>\n",
       "      <td>P</td>\n",
       "      <td>The Academy has brought nothing but useful and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   I/E N/S T/F J/P                                              Essay\n",
       "0    I   S   T   J  My first 4 months at the EDSA have been filled...\n",
       "1    I   N   F   J  I joined the academy being at a crossroads of ...\n",
       "2    E   N   F   J  so far my experience has been positive and i c...\n",
       "3    I   N   F   J  I have been very fortunate to have the opportu...\n",
       "4    I   N   T   J  Looking back to when one got to the academy an...\n",
       "..  ..  ..  ..  ..                                                ...\n",
       "89   I   S   F   J  My experience at the Explore Data Science Acad...\n",
       "90   I   N   T   P  A new city, new people and a completely new en...\n",
       "91   I   N   T   J  My experience at the academy has been one of t...\n",
       "92   I   S   F   J  After spending a year at home while it was jus...\n",
       "93   E   S   F   P  The Academy has brought nothing but useful and...\n",
       "\n",
       "[93 rows x 5 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b21d39a4-492c-4b06-99f4-bea989640c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>I/E</th>\n",
       "      <th>N/S</th>\n",
       "      <th>T/F</th>\n",
       "      <th>J/P</th>\n",
       "      <th>Essay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I</td>\n",
       "      <td>S</td>\n",
       "      <td>T</td>\n",
       "      <td>J</td>\n",
       "      <td>My first 4 months at the EDSA have been filled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>I joined the academy being at a crossroads of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>so far my experience has been positive and i c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>I have been very fortunate to have the opportu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>J</td>\n",
       "      <td>Looking back to when one got to the academy an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>89</td>\n",
       "      <td>I</td>\n",
       "      <td>S</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>My experience at the Explore Data Science Acad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>90</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>P</td>\n",
       "      <td>A new city, new people and a completely new en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>91</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>J</td>\n",
       "      <td>My experience at the academy has been one of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>92</td>\n",
       "      <td>I</td>\n",
       "      <td>S</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>After spending a year at home while it was jus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>93</td>\n",
       "      <td>E</td>\n",
       "      <td>S</td>\n",
       "      <td>F</td>\n",
       "      <td>P</td>\n",
       "      <td>The Academy has brought nothing but useful and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index I/E N/S T/F J/P                                              Essay\n",
       "0       0   I   S   T   J  My first 4 months at the EDSA have been filled...\n",
       "1       1   I   N   F   J  I joined the academy being at a crossroads of ...\n",
       "2       2   E   N   F   J  so far my experience has been positive and i c...\n",
       "3       3   I   N   F   J  I have been very fortunate to have the opportu...\n",
       "4       4   I   N   T   J  Looking back to when one got to the academy an...\n",
       "..    ...  ..  ..  ..  ..                                                ...\n",
       "89     89   I   S   F   J  My experience at the Explore Data Science Acad...\n",
       "90     90   I   N   T   P  A new city, new people and a completely new en...\n",
       "91     91   I   N   T   J  My experience at the academy has been one of t...\n",
       "92     92   I   S   F   J  After spending a year at home while it was jus...\n",
       "93     93   E   S   F   P  The Academy has brought nothing but useful and...\n",
       "\n",
       "[94 rows x 6 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "1a6833dd-22f7-4664-bd52-31d287ef91b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "def remove_stop_words(tokens):    \n",
    "    return \" \".join([token for token in tokens if token not in stop_words])\n",
    "\n",
    "translator = str.maketrans(string.punctuation, ' ' * len(string.punctuation))\n",
    "def remove_punctuation(post):\n",
    "    #return \"\".join([word if word not in punctuation else \" \" for word in post]).lower()\n",
    "    # Step 2: Remove punctuation and replace it with a single whitespace\n",
    "    return post.translate(translator).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d6b978c5-b8bc-4e9d-9fcc-c77b0c595b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Iâ€™m part-time student @explore-software.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'iâ€™m part time student  explore software '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'iâ€™m part time student  explore software '"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_stop_words = remove_stop_words(\"Iâ€™m a part-time student @explore-software.\".split())\n",
    "display(clean_stop_words)\n",
    "without_punct = remove_punctuation(clean_stop_words)\n",
    "display(without_punct)\n",
    "cleaned_text = without_punct\n",
    "cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "3064945d-22f8-432b-9c52-051917a9e33f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('iâ€™m', 'part'),\n",
       " ('part', 'time'),\n",
       " ('time', 'student'),\n",
       " ('student', 'explore'),\n",
       " ('explore', 'software')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[('iâ€™m', 'part'),\n",
       " ('part', 'time'),\n",
       " ('time', 'student'),\n",
       " ('student', 'explore'),\n",
       " ('explore', 'software')]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display([gram for gram in ngrams(cleaned_text.split(),2)])\n",
    "list(ngrams(sentence.split(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "4a631347-bd71-4dee-995f-9e1eed98fb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ultracode/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Iâ€™m', 'part-time', 'student', '@explore-software.']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Iâ€™m part time student  explore software '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'iâ€™m part time student  explore software '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bi-grams: [('iâ€™m', 'part'), ('part', 'time'), ('time', 'student'), ('student', 'explore'), ('explore', 'software')]\n",
      "Number of bi-grams: 5\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "import nltk\n",
    "\n",
    "# Download stopwords if not already downloaded\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Given sentence\n",
    "sentence = \"Iâ€™m a part-time student @explore-software.\"\n",
    "\n",
    "# Step 3: Split sentence into words\n",
    "words = sentence.split()\n",
    "\n",
    "# Step 4: Remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_words = [word for word in words if word not in stop_words]\n",
    "display(filtered_words)\n",
    "\n",
    "# Step 2: Remove punctuation and replace it with a single whitespace\n",
    "# str.maketrans(from, to): This method creates a translation table that maps each \n",
    "# character in the from string to the corresponding character in the to string.\n",
    "# string.punctuation: The from string containing all punctuation characters.\n",
    "# ' ' * len(string.punctuation): The to string is a series of spaces of the same length\n",
    "# as the from string. This means each punctuation character will be replaced by a space.\n",
    "translator = str.maketrans(string.punctuation, \" \" * len(string.punctuation))\n",
    "sentence = \" \".join(filtered_words).translate(translator)\n",
    "display(sentence)\n",
    "\n",
    "# Step 1: Convert all text to lowercase\n",
    "sentence = sentence.lower()\n",
    "display(sentence)\n",
    "\n",
    "# Step 5: Create bi-grams\n",
    "bigrams = list(ngrams(sentence.split(), 2))\n",
    "\n",
    "# Output the bi-grams and their count\n",
    "print(\"Bi-grams:\", bigrams)\n",
    "print(\"Number of bi-grams:\", len(bigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ff4a39aa-5625-4513-b6b6-6a3517e89399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7127659574468085, 0.27956989247311825)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Intuitive_count = (essay[\"N/S\"] == \"N\").mean()\n",
    "sensing_count = essay[essay[\"N/S\"] == \"S\"][\"N/S\"].count()\n",
    "Intuitive_count, (sensing_count/(67+26))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6b259b76-e935-4500-9e0c-bd6d5aaa0b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my first 4'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay[\"Essay without punct\"] = essay[\"Essay\"].apply(remove_punctuation)\n",
    "essay[\"Essay without punct\"].iloc[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fc6eb35a-4b2f-4138-b8c1-7ec808a51d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "456"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = TreebankWordTokenizer()\n",
    "essay[\"Essay without punct\"] = essay[\"Essay\"].apply(tokenizer.tokenize)\n",
    "len(essay[\"Essay without punct\"].iloc[17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1aeab949-606f-4524-976f-2c70a24daf21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "340"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.tokenize(essay[\"Essay\"][16].translate(translator).lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ad396cb1-503c-4814-b1c1-066d4e0fa3e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'experi'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowball = SnowballStemmer('english')\n",
    "snowball.stem(\"experiences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8c59f926-b484-48a9-9723-86dfdff218b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['collaborated', 'ensured', 'done', 'times', 'working', 'lab', 'always']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eighty_first_words = [word for word in essay[\"Essay\"][80].split() if word not in stop_words]\n",
    "display(eighty_first_words[23:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "179ab403-8606-4fd1-bcd2-0c6d095a81c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My reflections in the Academy , it gets better and  better everytime, first few months were hard as i had it hard to adapt to the environment and the people i was placed with, but i am grateful for the support they always offered and how well we always collaborated and ensured that we do what had to be done at all times\\n\\nworking in the lab i always found it convenient as i can be able to ask any assistance from anybody close to me or any of the supervisors for clarity at any time given, working in teams is always challenging as we are different people who learn not the same way, some possess a certain skill, while others having other skill to prove and together in most cases it helped us a lot as we would share the work among ourselves and get the best results we could with what knew best\\n\\nWhen it comes to the decision making , in all the previous groups i participated in ,we always checked what was expected of us from the rubric, then we would either volunteer to do the parts of the projects individually or the team leader would delegate who does what and we will all sit down and see if ever they are all in line with whats needed,and fix where they need fixing, it would get rational as other people would feel they are not treated fairly and equally and the part of the work is not given much credit like others, and we always argued but at the end got a solution to it all, but all in all i am grateful of the experience and the skills i am still getting up to so far.'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay[\"Essay\"][80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "2ac49d99-43a6-44bb-9461-72817960466c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words (after removing stopwords): 3334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ultracode/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # redo\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# Download stopwords if not already downloaded\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Step 1: Load the data\n",
    "df = pd.read_csv('./Dataset/Essay_data.csv')\n",
    "\n",
    "# Step 2: Clean the data\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "# Step 3: Define helper functions for text processing\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    translator = str.maketrans(string.punctuation, ' ' * len(string.punctuation))\n",
    "    return text.translate(translator)\n",
    "\n",
    "def process_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = remove_punctuation(text)\n",
    "    # Split into words\n",
    "    words = text.split()\n",
    "    # Remove stopwords\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return filtered_words\n",
    "\n",
    "# Step 4: Process each essay and collect unique words\n",
    "unique_words = set()\n",
    "\n",
    "for essay in df['Essay']:  # Replace 'essay_column' with the actual column name containing the essays\n",
    "    words = process_text(essay)\n",
    "    unique_words.update(words)\n",
    "\n",
    "# Step 5: Count unique words\n",
    "num_unique_words = len(unique_words)\n",
    "\n",
    "print(f\"Number of unique words (after removing stopwords): {num_unique_words}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a7936172-9290-4312-bce0-02c72ec05929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bag_of_words_count(words, word_dict={}):\n",
    "    \"\"\"\n",
    "    This function takes in a list of words and returns a dictionary \n",
    "    with each word as a key, and the value represents the number of \n",
    "    times that word appeared\n",
    "    \"\"\"\n",
    "    for word in words:\n",
    "        if word in word_dict.keys():\n",
    "            word_dict[word] += 1\n",
    "        else:\n",
    "            word_dict[word] = 1\n",
    "    return word_dict\n",
    "\n",
    "bag_of_words_count(essay[\"Essay\"][55].split())[\"time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "deb12e42-1eb4-4865-a438-8027a2178fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of words that appear at least twice: 9.51%\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# Step 4: Process each essay and count word frequencies\n",
    "word_counter = Counter()\n",
    "\n",
    "for essay in df['Essay']:  # Replace 'essay' with the actual column name containing the essays\n",
    "    words = process_text(essay)\n",
    "    word_counter.update(words)\n",
    "\n",
    "# Step 5: Calculate the total number of words and the number of words that appear at least twice\n",
    "total_words = sum(word_counter.values())\n",
    "words_at_least_twice = sum(1 for count in word_counter.values() if count >= 2)\n",
    "\n",
    "# Calculate the percentage\n",
    "percentage = (words_at_least_twice / total_words) * 100\n",
    "\n",
    "print(f\"Percentage of words that appear at least twice: {percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "c211e9e1-d23e-4cb9-9d9d-e064a5d2d55d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('quite', 'well')"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(process_text(df[\"Essay\"][69]), 2))[108]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d958dd-e5ac-4227-86a8-e4ce534aaffd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
