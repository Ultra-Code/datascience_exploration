{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35b64f6b-3e1d-4c09-b560-b90ee1d8a54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk import SnowballStemmer, PorterStemmer, LancasterStemmer, download\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from string import punctuation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af5da71d-7c39-49dd-a499-682abd02b5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ultracode/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download stopwords if not already downloaded\n",
    "download(['stopwords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82fa5cb1-668d-402f-825b-021afe7c4d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I/E</th>\n",
       "      <th>N/S</th>\n",
       "      <th>T/F</th>\n",
       "      <th>J/P</th>\n",
       "      <th>Essay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>S</td>\n",
       "      <td>T</td>\n",
       "      <td>J</td>\n",
       "      <td>My first 4 months at the EDSA have been filled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>I joined the academy being at a crossroads of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>so far my experience has been positive and i c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>I have been very fortunate to have the opportu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>J</td>\n",
       "      <td>Looking back to when one got to the academy an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  I/E N/S T/F J/P                                              Essay\n",
       "0   I   S   T   J  My first 4 months at the EDSA have been filled...\n",
       "1   I   N   F   J  I joined the academy being at a crossroads of ...\n",
       "2   E   N   F   J  so far my experience has been positive and i c...\n",
       "3   I   N   F   J  I have been very fortunate to have the opportu...\n",
       "4   I   N   T   J  Looking back to when one got to the academy an..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Load the data\n",
    "essay = pd.read_csv(\"./Dataset/Essay_data.csv\")\n",
    "essay.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c245421e-a06d-465c-bc50-fc80ecafc85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "744fc332-f2c5-4805-942a-ba48dfc6b15b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I/E</th>\n",
       "      <th>N/S</th>\n",
       "      <th>T/F</th>\n",
       "      <th>J/P</th>\n",
       "      <th>Essay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>S</td>\n",
       "      <td>T</td>\n",
       "      <td>J</td>\n",
       "      <td>My first 4 months at the EDSA have been filled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>I joined the academy being at a crossroads of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>so far my experience has been positive and i c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>I have been very fortunate to have the opportu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>J</td>\n",
       "      <td>Looking back to when one got to the academy an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>I</td>\n",
       "      <td>S</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>My experience at the Explore Data Science Acad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>P</td>\n",
       "      <td>A new city, new people and a completely new en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>J</td>\n",
       "      <td>My experience at the academy has been one of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>I</td>\n",
       "      <td>S</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>After spending a year at home while it was jus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>E</td>\n",
       "      <td>S</td>\n",
       "      <td>F</td>\n",
       "      <td>P</td>\n",
       "      <td>The Academy has brought nothing but useful and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   I/E N/S T/F J/P                                              Essay\n",
       "0    I   S   T   J  My first 4 months at the EDSA have been filled...\n",
       "1    I   N   F   J  I joined the academy being at a crossroads of ...\n",
       "2    E   N   F   J  so far my experience has been positive and i c...\n",
       "3    I   N   F   J  I have been very fortunate to have the opportu...\n",
       "4    I   N   T   J  Looking back to when one got to the academy an...\n",
       "..  ..  ..  ..  ..                                                ...\n",
       "89   I   S   F   J  My experience at the Explore Data Science Acad...\n",
       "90   I   N   T   P  A new city, new people and a completely new en...\n",
       "91   I   N   T   J  My experience at the academy has been one of t...\n",
       "92   I   S   F   J  After spending a year at home while it was jus...\n",
       "93   E   S   F   P  The Academy has brought nothing but useful and...\n",
       "\n",
       "[93 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Clean the data\n",
    "essay.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b21d39a4-492c-4b06-99f4-bea989640c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>I/E</th>\n",
       "      <th>N/S</th>\n",
       "      <th>T/F</th>\n",
       "      <th>J/P</th>\n",
       "      <th>Essay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I</td>\n",
       "      <td>S</td>\n",
       "      <td>T</td>\n",
       "      <td>J</td>\n",
       "      <td>My first 4 months at the EDSA have been filled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>I joined the academy being at a crossroads of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>so far my experience has been positive and i c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>I have been very fortunate to have the opportu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>J</td>\n",
       "      <td>Looking back to when one got to the academy an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>89</td>\n",
       "      <td>I</td>\n",
       "      <td>S</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>My experience at the Explore Data Science Acad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>90</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>P</td>\n",
       "      <td>A new city, new people and a completely new en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>91</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>J</td>\n",
       "      <td>My experience at the academy has been one of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>92</td>\n",
       "      <td>I</td>\n",
       "      <td>S</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>After spending a year at home while it was jus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>93</td>\n",
       "      <td>E</td>\n",
       "      <td>S</td>\n",
       "      <td>F</td>\n",
       "      <td>P</td>\n",
       "      <td>The Academy has brought nothing but useful and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index I/E N/S T/F J/P                                              Essay\n",
       "0       0   I   S   T   J  My first 4 months at the EDSA have been filled...\n",
       "1       1   I   N   F   J  I joined the academy being at a crossroads of ...\n",
       "2       2   E   N   F   J  so far my experience has been positive and i c...\n",
       "3       3   I   N   F   J  I have been very fortunate to have the opportu...\n",
       "4       4   I   N   T   J  Looking back to when one got to the academy an...\n",
       "..    ...  ..  ..  ..  ..                                                ...\n",
       "89     89   I   S   F   J  My experience at the Explore Data Science Acad...\n",
       "90     90   I   N   T   P  A new city, new people and a completely new en...\n",
       "91     91   I   N   T   J  My experience at the academy has been one of t...\n",
       "92     92   I   S   F   J  After spending a year at home while it was jus...\n",
       "93     93   E   S   F   P  The Academy has brought nothing but useful and...\n",
       "\n",
       "[94 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1a6833dd-22f7-4664-bd52-31d287ef91b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "translator = str.maketrans(punctuation, ' ' * len(punctuation))\n",
    "\n",
    "# Step 3: Define helper functions for text processing\n",
    "def remove_stop_words(tokens):    \n",
    "    return \" \".join([token for token in tokens.split() if token not in stop_words])\n",
    "\n",
    "def remove_punctuation(post):\n",
    "    #return \"\".join([word if word not in punctuation else \" \" for word in post]).lower()\n",
    "    # Step 2: Remove punctuation and replace it with a single whitespace\n",
    "    return post.translate(translator).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6b978c5-b8bc-4e9d-9fcc-c77b0c595b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I’m part-time student @explore-software.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'i’m part time student  explore software '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'i’m part time student  explore software '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_stop_words = remove_stop_words(\"I’m a part-time student @explore-software.\".split())\n",
    "display(clean_stop_words)\n",
    "without_punct = remove_punctuation(clean_stop_words)\n",
    "display(without_punct)\n",
    "cleaned_text = without_punct\n",
    "cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3064945d-22f8-432b-9c52-051917a9e33f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i’m', 'part'),\n",
       " ('part', 'time'),\n",
       " ('time', 'student'),\n",
       " ('student', 'explore'),\n",
       " ('explore', 'software')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display([gram for gram in ngrams(cleaned_text.split(),2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a631347-bd71-4dee-995f-9e1eed98fb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import string\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.util import ngrams\n",
    "# import nltk\n",
    "\n",
    "# # Download stopwords if not already downloaded\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# Given sentence\n",
    "# sentence = \"I’m a part-time student @explore-software.\"\n",
    "\n",
    "# # Step 3: Split sentence into words\n",
    "# words = sentence.split()\n",
    "\n",
    "# # Step 4: Remove stopwords\n",
    "# stop_words = set(stopwords.words('english'))\n",
    "# filtered_words = [word for word in words if word not in stop_words]\n",
    "# display(filtered_words)\n",
    "\n",
    "# # Step 2: Remove punctuation and replace it with a single whitespace\n",
    "# # str.maketrans(from, to): This method creates a translation table that maps each \n",
    "# # character in the from string to the corresponding character in the to string.\n",
    "# # string.punctuation: The from string containing all punctuation characters.\n",
    "# # ' ' * len(string.punctuation): The to string is a series of spaces of the same length\n",
    "# # as the from string. This means each punctuation character will be replaced by a space.\n",
    "# translator = str.maketrans(string.punctuation, \" \" * len(string.punctuation))\n",
    "# sentence = \" \".join(filtered_words).translate(translator)\n",
    "# display(sentence)\n",
    "\n",
    "# # Step 1: Convert all text to lowercase\n",
    "# sentence = sentence.lower()\n",
    "# display(sentence)\n",
    "\n",
    "# # Step 5: Create bi-grams\n",
    "# bigrams = list(ngrams(sentence.split(), 2))\n",
    "\n",
    "# # Output the bi-grams and their count\n",
    "# print(\"Bi-grams:\", bigrams)\n",
    "# print(\"Number of bi-grams:\", len(bigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff4a39aa-5625-4513-b6b6-6a3517e89399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7127659574468085, 0.27956989247311825)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Intuitive_count = (essay[\"N/S\"] == \"N\").mean()\n",
    "sensing_count = essay[essay[\"N/S\"] == \"S\"][\"N/S\"].count()\n",
    "Intuitive_count, (sensing_count/(67+26))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b259b76-e935-4500-9e0c-bd6d5aaa0b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my first 4'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay[\"Essay without punct\"] = essay[\"Essay\"].apply(remove_punctuation)\n",
    "essay[\"Essay without punct\"].iloc[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc6eb35a-4b2f-4138-b8c1-7ec808a51d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many tokens are in the 17th essay 340\n"
     ]
    }
   ],
   "source": [
    "tokenizer = TreebankWordTokenizer()\n",
    "def tokenize_essay(essay):\n",
    "    return \" \".join(tokenizer.tokenize(essay))\n",
    "    \n",
    "\n",
    "essay[\"Clean Text\"] = essay[\"Essay without punct\"].apply(tokenize_essay)\n",
    "\n",
    "print(f\"How many tokens are in the 17th essay {len(essay[\"Clean Text\"].iloc[16].split())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1aeab949-606f-4524-976f-2c70a24daf21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "340"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.tokenize(essay[\"Essay\"][16].translate(translator).lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad396cb1-503c-4814-b1c1-066d4e0fa3e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'experi'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowball = SnowballStemmer('english')\n",
    "snowball.stem(\"experiences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c59f926-b484-48a9-9723-86dfdff218b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'times'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stop_words(essay[\"Clean Text\"][80].split()).split()[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f7bc0938-3b4e-4373-8b93-9ebe0395bc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text_to_string(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = remove_punctuation(text)\n",
    "    # Split into words\n",
    "    words = text.split()\n",
    "    # Remove stopwords\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return \" \".join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "25fceb6c-90b3-470d-ab94-0108b0485a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'experience edsa interesting one thus far pushed get shell interact people since academy realised smarter think lot valuable knowledge insight share biggest fear coming academy social aspect interact different people since able overcome fear first placed groups literally sweating heart rate high felt sick stomach idea group strangers second time split new groups wasn’t nervous become social enjoy meeting working new people working groups challenge frustrating everyone different everyone different approach learning process project management i’ve learned lot working others took backseat things even knew better way things spoke saw helped team steer team better direction become assertive thought passive person couldn’t assertive save life think assertive don’t find daunting biggest frustration working teams dealing people think know everything aren’t willing open learning something new fellow teammates person like previous group person would dictate team didn’t want collaborate team dominating personality rest us shy realised none us didn’t speak we’d fail sprint forced breakout shyness think still fairly shy comes work fight shyness decisions previous group initially made one person prefer problems discussed everyone team different possible solutions explored come collaborative solution found current team still issues people letting pride emotions get way work people distracted aren’t committed project working labs challenge lot distractions noise focus easily prefer work home get much done home people come academy socialise anything distracting'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay[\"Cleaner\"] = essay[\"Clean Text\"].apply(process_text_to_string)\n",
    "essay[\"Cleaner\"].iloc[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2ac49d99-43a6-44bb-9461-72817960466c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words (after removing stopwords): 3339\n"
     ]
    }
   ],
   "source": [
    "def process_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = remove_punctuation(text)\n",
    "    # Split into words\n",
    "    words = text.split()\n",
    "    # Remove stopwords\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return filtered_words\n",
    "\n",
    "# Step 4: Process each essay and collect unique words\n",
    "unique_words = set()\n",
    "\n",
    "for text in essay['Cleaner']:  # Replace 'essay_column' with the actual column name containing the essays\n",
    "    words = process_text(text)\n",
    "    unique_words.update(words)\n",
    "    \n",
    "# Step 5: Count unique words\n",
    "num_unique_words = len(unique_words)\n",
    "print(f\"Number of unique words (after removing stopwords): {num_unique_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a7936172-9290-4312-bce0-02c72ec05929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bag_of_words_count(words, word_dict={}):\n",
    "    \"\"\"\n",
    "    This function takes in a list of words and returns a dictionary \n",
    "    with each word as a key, and the value represents the number of \n",
    "    times that word appeared\n",
    "    \"\"\"\n",
    "    for word in words:\n",
    "        if word in word_dict.keys():\n",
    "            word_dict[word] += 1\n",
    "        else:\n",
    "            word_dict[word] = 1\n",
    "    return word_dict\n",
    "\n",
    "bag_of_words_count(essay[\"Cleaner\"][55].split())[\"time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "deb12e42-1eb4-4865-a438-8027a2178fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of words that appear at least twice: 90.36%\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# Step 4: Process each essay and count word frequencies\n",
    "word_counter = Counter()\n",
    "\n",
    "for text in essay['Cleaner']:  # Replace 'essay' with the actual column name containing the essays\n",
    "    words = process_text(text)\n",
    "    word_counter.update(words)\n",
    "\n",
    "# Step 5: Calculate the total number of words and the number of words that appear at least twice\n",
    "total_words = sum(word_counter.values())\n",
    "words_at_least_twice = sum(count for count in word_counter.values() if count >= 2)\n",
    "\n",
    "# Calculate the percentage\n",
    "percentage = (words_at_least_twice / total_words) * 100\n",
    "\n",
    "print(f\"Percentage of words that appear at least twice: {percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "91fe5e6d-bd9f-4e4d-bfc8-e14da29917c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I/E</th>\n",
       "      <th>N/S</th>\n",
       "      <th>T/F</th>\n",
       "      <th>J/P</th>\n",
       "      <th>Cleaner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>S</td>\n",
       "      <td>T</td>\n",
       "      <td>J</td>\n",
       "      <td>first 4 months edsa filled many new experience...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>joined academy crossroads sorts life academy o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>far experience positive definitely see value c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>fortunate opportunity join academy year sure c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>J</td>\n",
       "      <td>looking back one got academy right confidently...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  I/E N/S T/F J/P                                            Cleaner\n",
       "0   I   S   T   J  first 4 months edsa filled many new experience...\n",
       "1   I   N   F   J  joined academy crossroads sorts life academy o...\n",
       "2   E   N   F   J  far experience positive definitely see value c...\n",
       "3   I   N   F   J  fortunate opportunity join academy year sure c...\n",
       "4   I   N   T   J  looking back one got academy right confidently..."
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_essay = essay[[\"I/E\",\"N/S\",\"T/F\",\"J/P\",\"Cleaner\"]]\n",
    "clean_essay.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "843b56ca-2d5b-4dd8-9de9-882e0121de56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('team', 336)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enfj = clean_essay[(clean_essay[\"I/E\"]==\"E\") | (clean_essay[\"N/S\"]==\"N\") | (clean_essay[\"T/F\"]==\"F\") | (clean_essay[\"J/P\"]==\"J\") ]\n",
    "enfj_word_counter = Counter()\n",
    "\n",
    "for text in enfj['Cleaner']:  # Replace 'essay' with the actual column name containing the essays\n",
    "    words = process_text(text)\n",
    "    enfj_word_counter.update(words)\n",
    "\n",
    "enfj_word_counter.most_common(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e57fdfba-9a2f-48e2-a663-3901d3024cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('may', 'better')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(process_text(essay[\"Cleaner\"][69]), 2))[108]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
