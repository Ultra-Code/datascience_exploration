{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/Python-Notebook-Banners/Code_challenge.png\"  style=\"display: block; margin-left: auto; margin-right: auto;\";/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Image classification MCQ \n",
    "© ExploreAI Academy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The versatile machine learning techniques you have been learning will enable you to process complex and different data at a faster pace.  \n",
    "\n",
    "So far you have performed classification on both tabular  ([iris dataset](https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html)) and textual data ([the mbti dataset](https://www.kaggle.com/datasnaek/mbti-type)). In this notebook, you will apply the machine learning techniques you have learned for image classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Let's go ahead and load our libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gzip # This is used in extracting the images\n",
    "\n",
    "import matplotlib.pyplot as plt # In order to plot the images to see what we are dealing with\n",
    "from sklearn.ensemble import RandomForestClassifier # You'll be using Random Forest to classify the images\n",
    "from sklearn.metrics import accuracy_score # Sklearn's way of measuring accuracy\n",
    "from sklearn.metrics import classification_report "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# The data\n",
    "\n",
    "The dataset we will be using is called `MNIST`. This is a large collection of hand-drawn digits `0 to 9` and is a good dataset to learn image classification on as it requires little to no preprocessing.\n",
    "\n",
    "The dataset can be downloaded from [The MNIST Database](https://web.archive.org/web/20220331130319/https://yann.lecun.com/exdb/mnist/). Download all four files. These files are the images and their respective labels (normally, we're required to split the x (image data / characteristics) and y (labels) out during preprocessing, but this has already been done for us). The dataset has also already been split into a train and a test set.\n",
    "\n",
    "Once you've downloaded the data, make sure that the data are in the same folder as this Jupyter notebook. If you've managed to do all that, we can now begin! \n",
    "\n",
    "By default, the MNIST files are compressed in the gzip format. The following two functions will extract the data for you. ** **Don't change this code.** **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(filename, num_images, IMAGE_WIDTH):\n",
    "    \"\"\"Extract the images into a 4D tensor [image index, y, x, channels].\"\"\"\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(16)\n",
    "        buf = bytestream.read(IMAGE_WIDTH * IMAGE_WIDTH * num_images)\n",
    "        data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "        data = data.reshape(num_images, IMAGE_WIDTH*IMAGE_WIDTH)\n",
    "        return data\n",
    "\n",
    "def extract_labels(filename, num_images):\n",
    "    \"\"\"Extract the labels into a vector of int64 label IDs.\"\"\"\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(8)\n",
    "        buf = bytestream.read(1 * num_images)\n",
    "        labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 1: Extracting the data\n",
    "\n",
    "The MNIST dataset consists of 60,000 training images and 10,000 testing images. This is a lot of data! Let's not extract all of that right now. Create a function `get_data` that uses the above functions to extract a certain number of images and their labels from the gzip files.\n",
    "\n",
    "The function will take as input two integer values, the number of train and test images to be extracted. Let's extract `5000` train images and `1000` test images. The function then returns four variables in the form of `(X_train, y_train), (X_test, y_test)`, where `(X_train, y_train)` are the extracted images and labels of the training set, and `(X-test, y_test)` are the extracted images and labels of the testing set. (Hint – you'll have to use the functions provided more than once.) \n",
    "\n",
    "Image pixel values range from 0 to 255. We need to normalise the image pixels so that they are in the range 0 to 1.\n",
    "\n",
    "_**Function specifications:**_\n",
    "* Should take two integers as input, one representing the number of training images and the other the number of testing images.\n",
    "* Should return two `tuples` of the form `(X_train, y_train), (X_test, y_test)`.\n",
    "\n",
    "_**Note**_ that the size of the MNIST images is 28x28.\n",
    "\n",
    "Usually when setting up your dataset, it is a good idea to randomly shuffle your data in case your data are ordered. Think of this as shuffling a pack of cards. Here, however, we aren't going to shuffle the data so that all our answers are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def get_data(num_train_images,num_test_images):\n",
    "    #your code here\n",
    "    X_train /= 255.0\n",
    "    \n",
    "    #your code here\n",
    "    X_test /= 255.0\n",
    "    return (X_train, y_train), (X_test, y_test)\n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the data\n",
    "\n",
    "Let's see what this data looks like! Right now the images are \"flattened\" into a 1-D array of length 784. In order to plot the image we first need to reshape it to the correct size of 28x28. We'll print out the respective label to make sure we are plotting the right number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_index = 3 ## Change me to view different images\n",
    "\n",
    "print(\"Label: \", y_train[image_index])\n",
    "reshaped_image = X_train[image_index].reshape((28, 28))\n",
    "\n",
    "plt.imshow(reshaped_image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 2: Training the model\n",
    "\n",
    "Now that we have formatted our data, we can fit a model using sklearn's `RandomForestClassifier` class with `20 estimators` and its `random_state` set to `42`. We'll write a function that will take as input the image and label variables that we created previously, and return a trained model.\n",
    "\n",
    "_**Function specifications:**_\n",
    "* Should take two NumPy `arrays` as input in the form `(X_train, y_train)`.\n",
    "* Should return an sklearn `RandomForestClassifier` model which has a random state of 42 and number of estimators 20.\n",
    "* The returned model should be fitted to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def train_model(X_train, y_train):\n",
    "    #your code here\n",
    "    return \n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = train_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 3: Testing the model\n",
    "\n",
    "Now that you have trained your model, let's see how well it does on the test set. Write a function which returns the accuracy of our trained model when tested with the test set.\n",
    "\n",
    "_**Function specifications:**_\n",
    "* Should take the fitted model `clf` and two NumPy arrays `X_test, y_test` as input.\n",
    "* Should return a `float` of the accuracy of the model. This number should be between zero and one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def calculate_accuracy(clf, X_test, y_test):\n",
    "    #your code here\n",
    "    return \n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calculate_accuracy(clf,X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification reports give us more information on where our model is going wrong – looking specifically at the performance caused by Type I and II errors. Write a function that returns the classification report of your test set.\n",
    "\n",
    "_**Function specifications:**_\n",
    "* Should take the fitted model `clf` and two NumPy arrays `X_test, y_test` as input.\n",
    "* Should return a classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def get_class_report(clf, X_test, y_test):\n",
    "    #your code here\n",
    "    return\n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_class_report(clf,X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the results\n",
    "\n",
    "Let's actually see if our model has trained correctly. To do so, plot some of the images with their predicted labels. Since we don't have the predictions stored in our notebook's memory, we need to call the predict function here first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(X_test)\n",
    "\n",
    "image_index = 15 ## Change me to see other predictions\n",
    "\n",
    "print(\"Predicted Label: \",preds[image_index])\n",
    "plt.imshow(X_test[image_index].reshape((28, 28)), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we didn't use all the data in the beginning, there is a chance our performance can improve. Go change the amount of data we use to see how it affects the accuracy of your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \n",
    "\n",
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/ExploreAI_logos/EAI_Blue_Dark.png\"  style=\"width:200px\";/>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
