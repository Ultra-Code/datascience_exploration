{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "250ac15e",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/Python-Notebook-Banners/Code_challenge.png\"  style=\"display: block; margin-left: auto; margin-right: auto;\";/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f662d169",
   "metadata": {},
   "source": [
    "# Graded code challenge: Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26af890c",
   "metadata": {},
   "source": [
    "⚠️ **NOTE that this code challenge is graded and will contribute to your overall marks for this module**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d230d14",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Learning objectives\n",
    "\n",
    "By the end of this coding challenge, you should be able to;\n",
    "- Implement a logistic regression model from scratch to solve a classification problem.\n",
    "- Apply learned concepts to preprocess data, fit the model, and evaluate its performance.\n",
    "- Enhance problem-solving skills by addressing a real-world classification challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68e80a4",
   "metadata": {},
   "source": [
    "## Honour Code\n",
    "\n",
    "I **YOUR NAME**, **YOUR SURNAME**, confirm - by submitting this document - that the solutions in this notebook are a result of my own work and that I abide by the EDSA honour code (https://drive.google.com/file/d/1QDCjGZJ8-FmJE3bZdIQNwnJyQKPhHZBn/view?usp=sharing).\n",
    "\n",
    "## Overview\n",
    "\n",
    "Within this coding challenge, we begin our practical experience of building models for classification problems. We do so with a basic Logistic Regression model.   \n",
    "\n",
    "<br></br>\n",
    "\n",
    "<div align=\"center\" style=\"width: 600px; font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/credit_card.jpg\"\n",
    "     alt=\"Learn good habits to avoid modelling debt\"\n",
    "     style=\"float: center; padding-bottom=0.5em\"\n",
    "     width=600px/>\n",
    "Learn good habits to avoid modelling debt... Photo by <a href=\"https://unsplash.com/@rupixen?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\"> Rupixen.com </a> on Unsplash.\n",
    "</div>\n",
    "\n",
    "The structure of this notebook is as follows:\n",
    "\n",
    " - First, we will start off by loading and viewing the dataset.\n",
    " - We will see that the dataset has a mixture of both numerical and non-numerical features; that it contains values from different ranges; and that it contains a number of missing entries.\n",
    " - Based upon the observations above, we will preprocess the dataset to ensure the machine learning model we choose can make good predictions.\n",
    " - Once our data is in good shape, we will do some exploratory data analysis to build our intuitions.\n",
    " - Finally, we will build a machine learning model that can predict if an individual's application for a credit card will be accepted.\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b63dda70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, precision_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0480d7ef",
   "metadata": {},
   "source": [
    "## The Dataset\n",
    "We'll use the [Credit Card Approval dataset](http://archive.ics.uci.edu/ml/datasets/credit+approval) from the UCI Machine Learning Repository.\n",
    "    \n",
    "We explore the variables within this dataset in the sections below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b80c841",
   "metadata": {},
   "source": [
    "### Reading in the data\n",
    "\n",
    "First, loading and viewing the dataset. We find that since this data are confidential, the contributor of the dataset has anonymized the feature names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "977b6832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00202</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00043</td>\n",
       "      <td>560</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>1.50</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00280</td>\n",
       "      <td>824</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00100</td>\n",
       "      <td>3</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>00120</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  0      1      2  3  4  5  6     7  8  9   10 11 12     13   14 15\n",
       "0  b  30.83  0.000  u  g  w  v  1.25  t  t   1  f  g  00202    0  +\n",
       "1  a  58.67  4.460  u  g  q  h  3.04  t  t   6  f  g  00043  560  +\n",
       "2  a  24.50  0.500  u  g  q  h  1.50  t  f   0  f  g  00280  824  +\n",
       "3  b  27.83  1.540  u  g  w  v  3.75  t  t   5  t  g  00100    3  +\n",
       "4  b  20.17  5.625  u  g  w  v  1.71  t  f   0  f  s  00120    0  +"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('https://raw.githubusercontent.com/Explore-AI/Public-Data/89fee4463f428f55d31a254924e18501a3c468c3/Data/classification_sprint/cc_approvals.data',header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c798da3",
   "metadata": {},
   "source": [
    "The output may appear a bit confusing at first glance, but let's try to figure out the most important features of a credit card application. The features of this dataset have been anonymized to protect the privacy, but [this blog](http://rstudio-pubs-static.s3.amazonaws.com/73039_9946de135c0a49daa7a0a9eda4a67a72.html) gives us a pretty good overview of the probable features. The probable features in a typical credit card application are <code>Gender</code>, <code>Age</code>, <code>Debt</code>, <code>Married</code>, <code>BankCustomer</code>, <code>EducationLevel</code>, <code>Ethnicity</code>, <code>YearsEmployed</code>, <code>PriorDefault</code>, <code>Employed</code>, <code>CreditScore</code>, <code>DriversLicense</code>, <code>Citizen</code>, <code>ZipCode</code>, <code>Income</code> and finally the <code>ApprovalStatus</code>. \n",
    "\n",
    "This gives us a pretty good starting point, and we can map these features with respect to the columns in the output.   \n",
    "\n",
    "As we can see from our first glance at the data, the dataset has a mixture of numerical and non-numerical features. This can be fixed with some preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9e75c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>b</td>\n",
       "      <td>47.17</td>\n",
       "      <td>5.835</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>5.500</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00465</td>\n",
       "      <td>150</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>b</td>\n",
       "      <td>25.83</td>\n",
       "      <td>12.835</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>cc</td>\n",
       "      <td>v</td>\n",
       "      <td>0.500</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00000</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>a</td>\n",
       "      <td>50.25</td>\n",
       "      <td>0.835</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>aa</td>\n",
       "      <td>v</td>\n",
       "      <td>0.500</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00240</td>\n",
       "      <td>117</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>?</td>\n",
       "      <td>29.50</td>\n",
       "      <td>2.000</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>e</td>\n",
       "      <td>h</td>\n",
       "      <td>2.000</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00256</td>\n",
       "      <td>17</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>a</td>\n",
       "      <td>37.33</td>\n",
       "      <td>2.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>i</td>\n",
       "      <td>h</td>\n",
       "      <td>0.210</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00260</td>\n",
       "      <td>246</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>a</td>\n",
       "      <td>41.58</td>\n",
       "      <td>1.040</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>aa</td>\n",
       "      <td>v</td>\n",
       "      <td>0.665</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00240</td>\n",
       "      <td>237</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>a</td>\n",
       "      <td>30.58</td>\n",
       "      <td>10.665</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>0.085</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>12</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00129</td>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>b</td>\n",
       "      <td>19.42</td>\n",
       "      <td>7.250</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>m</td>\n",
       "      <td>v</td>\n",
       "      <td>0.040</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00100</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>a</td>\n",
       "      <td>17.92</td>\n",
       "      <td>10.210</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>ff</td>\n",
       "      <td>ff</td>\n",
       "      <td>0.000</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00000</td>\n",
       "      <td>50</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>a</td>\n",
       "      <td>20.08</td>\n",
       "      <td>1.250</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>c</td>\n",
       "      <td>v</td>\n",
       "      <td>0.000</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00000</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>b</td>\n",
       "      <td>19.50</td>\n",
       "      <td>0.290</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>0.290</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00280</td>\n",
       "      <td>364</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.000</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>d</td>\n",
       "      <td>h</td>\n",
       "      <td>3.000</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00176</td>\n",
       "      <td>537</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>b</td>\n",
       "      <td>17.08</td>\n",
       "      <td>3.290</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>i</td>\n",
       "      <td>v</td>\n",
       "      <td>0.335</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00140</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>b</td>\n",
       "      <td>36.42</td>\n",
       "      <td>0.750</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>d</td>\n",
       "      <td>v</td>\n",
       "      <td>0.585</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00240</td>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>b</td>\n",
       "      <td>40.58</td>\n",
       "      <td>3.290</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>m</td>\n",
       "      <td>v</td>\n",
       "      <td>3.500</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>s</td>\n",
       "      <td>00400</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>b</td>\n",
       "      <td>21.08</td>\n",
       "      <td>10.085</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>e</td>\n",
       "      <td>h</td>\n",
       "      <td>1.250</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00260</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>a</td>\n",
       "      <td>22.67</td>\n",
       "      <td>0.750</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>c</td>\n",
       "      <td>v</td>\n",
       "      <td>2.000</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>2</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00200</td>\n",
       "      <td>394</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>a</td>\n",
       "      <td>25.25</td>\n",
       "      <td>13.500</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>ff</td>\n",
       "      <td>ff</td>\n",
       "      <td>2.000</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00200</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>b</td>\n",
       "      <td>17.92</td>\n",
       "      <td>0.205</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>aa</td>\n",
       "      <td>v</td>\n",
       "      <td>0.040</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00280</td>\n",
       "      <td>750</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>b</td>\n",
       "      <td>35.00</td>\n",
       "      <td>3.375</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>c</td>\n",
       "      <td>h</td>\n",
       "      <td>8.290</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00000</td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0      1       2  3  4   5   6      7  8  9   10 11 12     13   14 15\n",
       "670  b  47.17   5.835  u  g   w   v  5.500  f  f   0  f  g  00465  150  -\n",
       "671  b  25.83  12.835  u  g  cc   v  0.500  f  f   0  f  g  00000    2  -\n",
       "672  a  50.25   0.835  u  g  aa   v  0.500  f  f   0  t  g  00240  117  -\n",
       "673  ?  29.50   2.000  y  p   e   h  2.000  f  f   0  f  g  00256   17  -\n",
       "674  a  37.33   2.500  u  g   i   h  0.210  f  f   0  f  g  00260  246  -\n",
       "675  a  41.58   1.040  u  g  aa   v  0.665  f  f   0  f  g  00240  237  -\n",
       "676  a  30.58  10.665  u  g   q   h  0.085  f  t  12  t  g  00129    3  -\n",
       "677  b  19.42   7.250  u  g   m   v  0.040  f  t   1  f  g  00100    1  -\n",
       "678  a  17.92  10.210  u  g  ff  ff  0.000  f  f   0  f  g  00000   50  -\n",
       "679  a  20.08   1.250  u  g   c   v  0.000  f  f   0  f  g  00000    0  -\n",
       "680  b  19.50   0.290  u  g   k   v  0.290  f  f   0  f  g  00280  364  -\n",
       "681  b  27.83   1.000  y  p   d   h  3.000  f  f   0  f  g  00176  537  -\n",
       "682  b  17.08   3.290  u  g   i   v  0.335  f  f   0  t  g  00140    2  -\n",
       "683  b  36.42   0.750  y  p   d   v  0.585  f  f   0  f  g  00240    3  -\n",
       "684  b  40.58   3.290  u  g   m   v  3.500  f  f   0  t  s  00400    0  -\n",
       "685  b  21.08  10.085  y  p   e   h  1.250  f  f   0  f  g  00260    0  -\n",
       "686  a  22.67   0.750  u  g   c   v  2.000  f  t   2  t  g  00200  394  -\n",
       "687  a  25.25  13.500  y  p  ff  ff  2.000  f  t   1  t  g  00200    1  -\n",
       "688  b  17.92   0.205  u  g  aa   v  0.040  f  f   0  f  g  00280  750  -\n",
       "689  b  35.00   3.375  u  g   c   h  8.290  f  f   0  t  g  00000    0  -"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f594337",
   "metadata": {},
   "source": [
    "\n",
    "<li>Our dataset contains both numeric and non-numeric data (specifically data that are of <code>float64</code>, <code>int64</code> and <code>object</code> types). Specifically, features 2, 7, 10 and 14 contain numeric values (of types float64, float64, int64 and int64, respectively) and all the other features contain non-numeric values.</li>\n",
    "<li>The dataset also contains values from several ranges. Some features have a value range of 0 - 28, some have a range of 2 - 67, and some have a range of 1017 - 100000.\n",
    "<li>Finally, the dataset has missing values, which we'll take care of in this task. The missing values in the dataset are labelled with '?', which can be seen in the last cell's output.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f12d37",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9defc19",
   "metadata": {},
   "source": [
    "## Question 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee85e1c6",
   "metadata": {},
   "source": [
    "Write a function to clean the given data. The function should:\n",
    "* Replace the '?'s with NaN.\n",
    "* Impute the missing values with mean imputation.\n",
    "* Impute the missing values of non-numeric columns with the most frequent values as present in the respective columns.\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take a pandas DataFrame and column name as input and return a list as an output.\n",
    "* The list should be a count of unique values in the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "64d3e002",
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def data_cleaning(data, column_name):\n",
    "    \"\"\"\n",
    "      This function cleans the data by replacing '?' with NaN,\n",
    "      imputing missing values with mean imputation for numeric features,\n",
    "      and most frequent value imputation for non-numeric features.\n",
    "    \n",
    "      Args:\n",
    "          df (pandas.DataFrame): The DataFrame containing the data to clean.\n",
    "    \n",
    "      Returns:\n",
    "          list: A list containing the count of unique values in each column after cleaning.\n",
    "    \"\"\"\n",
    "    # Replace '?' with NaN\n",
    "    data.replace('?', np.nan, inplace=True)\n",
    "    \n",
    "    # Impute missing values with mean for numeric columns\n",
    "    if data[column_name].dtype in ['int64', 'float64']:\n",
    "       data[column_name] = data[column_name].fillna(data[column_name].mean())\n",
    "    else:\n",
    "        # Impute missing values with mode for non-numeric columns\n",
    "        mode_val = data[column_name].mode()[0]\n",
    "        data[column_name] = data[column_name].fillna(mode_val)\n",
    "\n",
    "    # Return a list of unique values count in the column\n",
    "    return data[column_name].value_counts().tolist()\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4efe4082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[468, 210, 12]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaning(df, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e2e50b84-650e-4cb5-adf6-dec10305d84e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[395, 295]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaning(df, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d20508",
   "metadata": {},
   "source": [
    "_**Expected Outputs:**_\n",
    "    \n",
    "\n",
    ">```\n",
    "data_cleaning(df, 0) == [480, 210]\n",
    "data_cleaning(df, 9) == [395, 295]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8294d3aa",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bc5177",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1721f24e",
   "metadata": {},
   "source": [
    "Write a function to pre-process the data so that we can run it through the classifier. The function should:\n",
    "* Convert the non-numeric data into numeric using sklearn's ```labelEncoder``` \n",
    "* Drop the features 11 and 13 and convert the DataFrame to a NumPy array\n",
    "* Split the data into features and labels\n",
    "* Standardise the features using sklearn's ```MinMaxScaler```\n",
    "* Split the data into 80% training and 20% testing data.\n",
    "* Use the `train_test_split` method from `sklearn` to do this.\n",
    "* Set random_state to equal 42 for this internal method. \n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take a dataframe as input.\n",
    "* The input should be the raw unprocessed dataframe df.\n",
    "* Should return two `tuples` of the form `(X_train, y_train), (X_test, y_test)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fdb67622",
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def data_preprocess(df):\n",
    "    \"\"\"\n",
    "      This function preprocesses the data for a classifier.\n",
    "    \n",
    "      Args:\n",
    "          df (pandas.DataFrame): The DataFrame containing the raw data.\n",
    "    \n",
    "      Returns:\n",
    "          tuple: A tuple containing two tuples:\n",
    "              (X_train, y_train): Training features and labels.\n",
    "              (X_test, y_test): Testing features and labels.\n",
    "    \"\"\"\n",
    "    # Encode non-numeric features\n",
    "    le = LabelEncoder()\n",
    "    for col in df.select_dtypes(include=['object']):\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "    \n",
    "    # Drop features 11 and 13 (assuming zero-based indexing)\n",
    "    df = df.drop(columns=[11, 13])\n",
    "    \n",
    "    # Convert DataFrame to NumPy array\n",
    "    X = df.to_numpy()\n",
    "    \n",
    "    # Separate features and labels\n",
    "    y = X[:, -1]  # Assuming the last column is the label\n",
    "    X = X[:, :-1]  # All columns except the last are features\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = MinMaxScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    return (X_train, y_train), (X_test, y_test)\n",
    "    # Convert non-numeric data into numeric using LabelEncoder\n",
    "    #label_encoder = LabelEncoder()\n",
    "    #for col in df.columns:\n",
    "    #    if df[col].dtype == 'object':\n",
    "    #        df[col] = label_encoder.fit_transform(df[col])\n",
    "    \n",
    "    # Drop features 11 and 13\n",
    "    #df.drop(columns=[11, 13], inplace=True)\n",
    "    \n",
    "    # Convert DataFrame to a NumPy array\n",
    "    #data_array = df.values\n",
    "    \n",
    "    # Split the data into features and labels\n",
    "    #X = data_array[:, :-1]  # Features are all columns except the last one\n",
    "    #y = data_array[:, -1]   # Label is the last column\n",
    "    \n",
    "    # Standardize the features using MinMaxScaler\n",
    "    #scaler = MinMaxScaler()\n",
    "    #X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Split the data into 80% training and 20% testing data\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    #return (X_train, y_train), (X_test, y_test)\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3f7eb7c4-9c36-4b44-bbe8-509cc476294a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.25787966 0.48214286 1.         1.         0.42857143\n",
      "  0.33333333 0.         0.         0.         0.         0.\n",
      "  0.        ]]\n",
      "[1.]\n",
      "[[0.5        1.         0.05357143 0.66666667 0.33333333 0.42857143\n",
      "  0.33333333 0.         0.         1.         0.02985075 0.\n",
      "  0.00105   ]]\n",
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = data_preprocess(data)\n",
    "print(X_train[:1])\n",
    "print(y_train[:1])\n",
    "print(X_test[:1])\n",
    "print(y_test[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "80386b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.25787966 0.48214286 1.         1.         0.42857143\n",
      "  0.33333333 0.         0.         0.         0.         0.\n",
      "  0.        ]]\n",
      "[1.]\n",
      "[[0.5        1.         0.05357143 0.66666667 0.33333333 0.42857143\n",
      "  0.33333333 0.         0.         1.         0.02985075 0.\n",
      "  0.00105   ]]\n",
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = data_preprocess(data)\n",
    "print(X_train[:1])\n",
    "print(y_train[:1])\n",
    "print(X_test[:1])\n",
    "print(y_test[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13516e81",
   "metadata": {},
   "source": [
    "_**Expected Outputs:**_\n",
    "\n",
    "```python\n",
    "(X_train, y_train), (X_test, y_test) = data_preprocess(df)\n",
    "print(X_train[:2])\n",
    "print(y_train[:2])\n",
    "print(X_test[:2])\n",
    "print(y_test[:2])\n",
    "```\n",
    "\n",
    "> ```\n",
    "[[1.         0.25787966 0.48214286 1.         1.         0.42857143\n",
    "  0.33333333 0.         0.         0.         0.         0.\n",
    "  0.        ]]\n",
    "[1.]\n",
    "[[0.5        1.         0.05357143 0.66666667 0.33333333 0.42857143\n",
    "  0.33333333 0.         0.         1.         0.02985075 0.\n",
    "  0.00105   ]]\n",
    "[1.]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bd1d11",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ba988d",
   "metadata": {},
   "source": [
    "## Question 3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603febfb",
   "metadata": {},
   "source": [
    "Now that we have formatted our data, we can fit a model using sklearn's `LogisticRegression` class with solver 'lbfgs'. Write a function that will take as input `(X_train, y_train)` that we created previously, and return a trained model.\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take two numpy `arrays` as input in the form `(X_train, y_train)`.\n",
    "* The returned model should be fitted to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c62e219f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def train_model(X_train, y_train):\n",
    "  \"\"\"\n",
    "  This function trains a Logistic Regression model.\n",
    "\n",
    "  Args:\n",
    "      X_train (numpy.ndarray): Training features.\n",
    "      y_train (numpy.ndarray): Training labels.\n",
    "\n",
    "  Returns:\n",
    "      sklearn.linear_model.LogisticRegression: The trained Logistic Regression model.\n",
    "  \"\"\"\n",
    "  # Create and train the model\n",
    "  model = LogisticRegression(solver='lbfgs')\n",
    "  model.fit(X_train, y_train)\n",
    "\n",
    "  return model\n",
    "\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "77f66e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.518930427718782\n",
      "[[ 0.25123837 -0.22851285 -0.0231819   1.99522614  0.24508202 -0.29298661\n",
      "  -0.08928246 -0.83827587 -3.49094192 -1.07599381 -0.83859545  0.07420654\n",
      "  -1.31988688]]\n"
     ]
    }
   ],
   "source": [
    "lm = train_model(X_train, y_train)\n",
    "print(lm.intercept_[0])\n",
    "print(lm.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bd3417",
   "metadata": {},
   "source": [
    "_**Expected Outputs:**_\n",
    "\n",
    "```python\n",
    "lm = train_model(X_train, y_train)\n",
    "print(lm.intercept_[0])\n",
    "print(lm.coef_)\n",
    "```\n",
    "```\n",
    "1.5068926456005878\n",
    "[[ 0.25237869 -0.22847881 -0.01779302  2.00977742  0.23903441 -0.29504922\n",
    "  -0.08952344 -0.83468871 -3.48756932 -1.07648711 -0.83688921  0.07860585\n",
    "  -1.3077735 ]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da86dc23",
   "metadata": {},
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ab990a",
   "metadata": {},
   "source": [
    "### Question 3.2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5401ffb6",
   "metadata": {},
   "source": [
    "AUC - ROC curve is a performance measurement for classification problem at various thresholds settings. ROC is a probability curve and AUC represents degree or measure of separability. It tells how much model is capable of distinguishing between classes. Write a function which returns the roc auc score of your trained model when tested with the test set.\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take the fitted model and two numpy `arrays` `X_test, y_test` as input.\n",
    "* Should return a `float` of the roc auc score of the model. This number should be between zero and one.\n",
    "\n",
    "_**Hint**_  Use the positive class's probability as the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "556d5f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def roc_score(lm, X_test, y_test):\n",
    "  \"\"\"\n",
    "  This function calculates the ROC AUC score of the trained model.\n",
    "\n",
    "  Args:\n",
    "      model (sklearn.linear_model.LogisticRegression): The trained model.\n",
    "      X_test (numpy.ndarray): Testing features.\n",
    "      y_test (numpy.ndarray): Testing labels.\n",
    "\n",
    "  Returns:\n",
    "      float: The ROC AUC score of the model.\n",
    "  \"\"\"\n",
    "  # Predict probabilities of the positive class\n",
    "  y_pred_proba = lm.predict_proba(X_test)[:, 1]\n",
    "\n",
    "  # Calculate ROC AUC score\n",
    "  roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "  return roc_auc\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d6acddb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.886344537815126\n"
     ]
    }
   ],
   "source": [
    "print(roc_score(lm,X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1225354",
   "metadata": {},
   "source": [
    "_**Expected Outputs:**_\n",
    "    \n",
    "```python\n",
    "print(roc_score(lm,X_test,y_test))\n",
    "```\n",
    ">```\n",
    "0.8865546218487395\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a7ff9b",
   "metadata": {},
   "source": [
    "### Question 3.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8492d4",
   "metadata": {},
   "source": [
    "Write a function which calculates the Accuracy, Precision, Recall and F1 scores.\n",
    "\n",
    "_**Function Specifications:**_\n",
    "* Should take the fitted model and two numpy `arrays` `X_test, y_test` as input.\n",
    "* Should return a tuple in the form (`Accuracy`, `Precision`, `Recall`, `F1-Score`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "49bcaedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### START FUNCTION\n",
    "def scores(model, X_test, y_test):\n",
    "  \"\"\"\n",
    "  This function calculates accuracy, precision, recall, and F1-score of the trained model.\n",
    "\n",
    "  Args:\n",
    "      model (sklearn.linear_model.LogisticRegression): The trained model.\n",
    "      X_test (numpy.ndarray): Testing features.\n",
    "      y_test (numpy.ndarray): Testing labels.\n",
    "\n",
    "  Returns:\n",
    "      tuple: A tuple containing accuracy, precision, recall, and F1-score.\n",
    "  \"\"\"\n",
    "  # Make predictions\n",
    "  y_pred = model.predict(X_test)\n",
    "\n",
    "  # Calculate metrics\n",
    "  accuracy = accuracy_score(y_test, y_pred)\n",
    "  precision = precision_score(y_test, y_pred)\n",
    "  recall = recall_score(y_test, y_pred)\n",
    "  f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "  return accuracy, precision, recall, f1\n",
    "### END FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "31225569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.833333\n",
      "Precision: 0.846154\n",
      "Recall: 0.808824\n",
      "F1 score: 0.827068\n"
     ]
    }
   ],
   "source": [
    "(accuracy, precision, recall, f1) = scores(lm, X_test, y_test)    \n",
    "\n",
    "print('Accuracy: %f' % accuracy)\n",
    "print('Precision: %f' % precision)\n",
    "print('Recall: %f' % recall)\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b0b488",
   "metadata": {},
   "source": [
    "_**Expected Outputs:**_\n",
    "```python\n",
    "(accuracy, precision, recall, f1) = scores(lm,X_test,y_test)\n",
    "    \n",
    "print('Accuracy: %f' % accuracy)\n",
    "print('Precision: %f' % precision)\n",
    "print('Recall: %f' % recall)\n",
    "print('F1 score: %f' % f1)\n",
    "```\n",
    "> ```\n",
    "Accuracy: 0.833333\n",
    "Precision: 0.846154\n",
    "Recall: 0.808824\n",
    "F1 score: 0.827068\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fd094b-0fee-46f1-a4b8-73766813c42b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#  \n",
    "\n",
    "<div align=\"center\" style=\" font-size: 80%; text-align: center; margin: 0 auto\">\n",
    "<img src=\"https://raw.githubusercontent.com/Explore-AI/Pictures/master/ExploreAI_logos/EAI_Blue_Dark.png\"  style=\"width:200px\";/>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
